# -*- coding: utf-8 -*-
import scrapy
from categoriesm.items import CategoriesmItem
import unicodedata
import urllib
import urlparse

def url_fix(s, charset='utf-8'):

    if isinstance(s, unicode):
        s = s.encode(charset, 'ignore')
    scheme, netloc, path, qs, anchor = urlparse.urlsplit(s)
    path = urllib.quote(path, '/%')
    qs = urllib.quote_plus(qs, ':&=')

class CategmSpider(scrapy.Spider):
	name = "categM"
	allowed_domains = ["mangafox.me"]
	start_urls = ['http://www.mangafox.me/']
	# start_urls = ["http://www.mangahere.co/yuri/"+str(i) +".htm" for i in range (1,11)]

	def parse(self, response):
		for sel in response.xpath('//div[@class="directory_list"]'):
			manga_url = sel.xpath('//ul/li/div[@class="manga_text"]/div[@class="title"]/a/@href').extract()

		for i in range (0, len(manga_url)):
			item = CategoriesItem(link=manga_url[i],categ="yuri",site="mangahere")
			request = scrapy.Request(str(manga_url[i]),callback=self.parse_manga, meta={'item':item})
			#request.meta['item'] = item
			yield request


	def parse_manga(self, response):

		item = response.meta['item']

		#item['manga_link'] = response.url
		#Arrumar nome
		import unicodedata
		name = response.xpath('//div[@class="box_w clearfix"]/h1[@class="title"]/text()').extract()
		print name
		if len(name) > 0:       
			manga_name = unicodedata.normalize('NFKD', name[0]).encode('ASCII', 'ignore')
			print manga_name
			name = [x.lower() for x in manga_name]
			manga_name = ''.join(str(e) for e in name)
			import HTMLParser
			htmlp = HTMLParser.HTMLParser()
			manga_name = htmlp.unescape(manga_name)
		else:	
			manga_name = "unknown"
		#name = unicode(manga_name, 'unicode-escape')
		#manga_name = unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore')
		item['name'] = manga_name
		yield item
